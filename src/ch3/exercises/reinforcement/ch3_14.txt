"show that if d(n) is O(f(n)), then a * d(n) is O(f(n)) for any constant a > 0"

a * d(n) is growing by a constant. Constants are ignored, thus if d(n) is O(f(n),
then a*d(n) must also be O(f(n))